package xiatian.octopus.actor.fetcher

import akka.actor._
import akka.pattern.{ask, pipe}
import akka.util.Timeout
import xiatian.octopus.actor.store.StoreActor
import xiatian.octopus.actor.{EmptyFetchJob, Fetch, FetchFailure, FetchJob, FetchRequest, FetchResult, LookupActor, NormalFetchJob}

import scala.concurrent.ExecutionContext.Implicits.global
import scala.concurrent.Future
import scala.concurrent.duration._
import scala.language.postfixOps
import scala.util.{Failure, Success}


/**
  * ä¸€ä¸ªçˆ¬è™«å®¢æˆ·ç«¯ï¼Œ fetcherIdä¸ºå”¯ä¸€çš„ä»£å·
  *
  * @author Tian Xia
  *         Dec 03, 2016 23:28
  */
class FetchClientActor(remotePath: String, fetcherId: Int)
  extends LookupActor(remotePath) with ActorLogging {

  val store = context actorOf Props(new StoreActor())
  val crawler = context actorOf Props(new CrawlingActor(store))

  val NEW_REQUEST = FetchRequest(fetcherId)

  implicit val timeout = Timeout(10 seconds) //crawlerçš„æ—¶é—´
  val requestNew = "request"
  val tick = context.system.scheduler.schedule(
    0 millis,
    15000 millis,
    self,
    requestNew)
  //å¦‚æžœé•¿æ—¶é—´å¾—ä¸åˆ°æœåŠ¡å™¨çš„è¿”å›žç›¸åº”ï¼Œåˆ™è‡ªåŠ¨å‘é€NEW_REQUEST
  var lastReceivedTaskTime = System.currentTimeMillis()
  var emptyCount = 0

  override def active(master: ActorRef): Actor.Receive = {
    case op: FetchRequest => master ! op

    case `requestNew` =>
      //å¦‚æžœ5åˆ†é’Ÿå†…æ²¡æœ‰æŽ¥æ”¶åˆ°è¿‡ä»»åŠ¡ï¼Œåˆ™è‡ªåŠ¨å‘masterå‘èµ·ä»»åŠ¡è¯·æ±‚
      if (System.currentTimeMillis() - lastReceivedTaskTime > 300000)
        master ! NEW_REQUEST

    case result: FetchJob =>
      lastReceivedTaskTime = System.currentTimeMillis() //æ›´æ–°åŒæ­¥æ—¶é—´
      result match {
        case EmptyFetchJob() =>
          print("ðŸˆ³")
          emptyCount += 1
          val millis = 2000 + (emptyCount * 1000)
          //æœ€é•¿å»¶è¿Ÿ2åˆ†é’Ÿ
          val delay = if (millis > 120000) 12000 else millis
          Thread.sleep(delay)
          master ! NEW_REQUEST
        case NormalFetchJob(link, context, proxyHolder) =>
          log.debug(s"fetch: $link")
          print("\uD83D\uDE0A") // å–åˆ°æ­£å¸¸ä»»åŠ¡çš„ç¬¦å·ï¼šðŸ˜Š
          emptyCount = 0
          //æŒ‡å®š30ç§’çš„å»¶è¿Ÿ, è®¾ç½®è¾ƒé•¿çš„æ—¶é—´å»¶è¿Ÿï¼Œä¿è¯GCèƒ½å¤ŸåŠæ—¶å›žæ”¶å†…å­˜
          // å¦‚æžœä¾ç„¶æœ‰é—®é¢˜ï¼Œè€ƒè™‘åœ¨CrawlingActorä¸­é™åˆ¶æœ€é•¿çš„è¿è¡Œæ—¶é—´
          (crawler ? Fetch(link, fetcherId, context, proxyHolder)) (60 seconds)
            .mapTo[FetchResult]
            .recoverWith {
              case e =>
                e.printStackTrace()
                log.error(s"Fetch ${link.url} error ==> $e")
                Future {
                  FetchFailure(link, e.toString, fetcherId)
                }
            }
            .pipeTo(master)
            .onComplete {
              case Success(r) =>
                log.info(s"Crawled and send back to master: ${link.url}")
              case Failure(e) =>
                e.printStackTrace()
                log.error(s"Error crawling $link", e)
            }
      }

    case Terminated(`master`) =>
      if (log.isWarningEnabled) log.warning("Master terminated")

      sendIdentifyRequest()
      context.become(identifying)
    case ReceiveTimeout =>
    // ignore
  }

  override def afterActive(master: ActorRef): Unit = {
    master ! NEW_REQUEST
    println(s"\nFetcher $fetcherId has connected to the master")
  }

}
